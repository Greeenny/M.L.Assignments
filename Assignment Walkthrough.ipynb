{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8b8778",
   "metadata": {},
   "source": [
    "# Assignment 1 Loss Functions and Linear Models.\n",
    "\n",
    "### Reads data:\n",
    "file = file\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "\n",
    "### Renames Columns:\n",
    "df = df.rename(colums={'c1':'newc1','c2':'newc2'})\n",
    "\n",
    "\n",
    "### Drops columns\n",
    "\n",
    "\n",
    "### Prints first few rows of a dataframe (all columns)\n",
    "\n",
    "\n",
    "### Replaces values using iloc\n",
    "\n",
    "\n",
    "### Plots a scattermatrix using pandas.\n",
    "\n",
    "\n",
    "## Creates a function for predicting y given parameters and X\n",
    "\n",
    "\n",
    "### Creates an array of ones using np.ones\n",
    "\n",
    "\n",
    "## Creates a function to calculate loss of linear inputs. (Residuals, RSS, gradient)\n",
    "\n",
    "\n",
    "## Creates a function to create parameters which fit X to y. (TSS, R2)\n",
    "### Uses scipy optimize.minimize. \n",
    "\n",
    "\n",
    "## Takes data, creates x and y. Fits a model to the x and y.\n",
    "\n",
    "## Plots the with a scatter plot data, and plots a line graph of predictions along a line.\n",
    "\n",
    "\n",
    "## Creates a function to calculate LAD Loss, then uses the linear fitter to fit the same data to the LAD Loss. Plots the same way.\n",
    "\n",
    "\n",
    "## Uses sklearn to fit the data to a LinearRegression() model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555764c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7656de4",
   "metadata": {},
   "source": [
    "# Assignment 2 Maximum Likelihood\n",
    "\n",
    "## Uses exponential distribution as our underlying topic of probability. Finds the Negative Log Likelihood of this exponential.\n",
    "\n",
    "### Creates a function which takes in lambda and the y's then returns the negative log likelihood.\n",
    "\n",
    "\n",
    "### We will use lambda to be equal to our inputs times our parameters, aka X dot b. \n",
    "\n",
    "\n",
    "### Makes a function which fits X to y and returns the betas.\n",
    "\n",
    "\n",
    "### Squared residualfunction.This is a measure of the loss.\n",
    "\n",
    "\n",
    "### Fits the data, finds the error using the above.\n",
    "\n",
    "\n",
    "### Uses sklearn to create an OLS fit, find coefficients / parameters. Calculates squared residual. \n",
    "\n",
    "## Plots scatter plot / Line plot of data / predictions along range\n",
    "\n",
    "\n",
    "\n",
    "## Creates an OLS fit using sklearn but with (1, x, x^2) as the input parameters. Creates a curved fit instead of an exponential.\n",
    "\n",
    "### Creates plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccdcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve, auc, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "seed=0\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd71bf83",
   "metadata": {},
   "source": [
    "# Assignment 3 Classification with Logistic Regression\n",
    "\n",
    "\n",
    "Reads data. Prints top 8. Prints columns. Prints types of columns.\n",
    "\n",
    "### Checks if any null values are in a column. Fills them\n",
    "\n",
    "### Uses df.loc to turn values which are X to 1, and which aren't X to 0. (X being 'DrugY')\n",
    "\n",
    "### Changes all columns to be filled with ints.\n",
    "\n",
    "### Finds baseline accuracy by finding the True / True + False\n",
    "\n",
    "### Turns data into X and y's. Splits data using train_test_split.\n",
    "\n",
    "\n",
    "\n",
    "## Uses LogisticRegression from skl. Uses only two columns from the X's. Does this with Xnew = X[:,[0,1]]\n",
    "\n",
    "\n",
    "### Compute Performance function. Finds true pos / neg, false pos / neg. Returns accuracy, precision, sensitivity, specificity.\n",
    "\n",
    "\n",
    "### Uses logistic regression using l2 penalty \"Default\". Uses different tuning parameter (how hard does it penalize).\n",
    "\n",
    "\n",
    "### Creates a sigmoid function. Finds the result of that sigmoid using the x inputs and coefficients, and intercepts.\n",
    "\n",
    "\n",
    "## Plots ROC curves. Uses roc_curve(ytest, ytest_probabilities[:,1]) to find the false positive rate and true positive rate. Plots it with ax.plot(fpr,tpr)\n",
    "\n",
    "\n",
    "\n",
    "# Then uses fetch_openml to get data from a database. Makes a pipeline which standardizes the values, then uses SGDClassifier which trains a logistic regression with multiple inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c147eab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import t\n",
    "import matplotlib.pyplot as plt\n",
    "seed=1110\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fed5059",
   "metadata": {},
   "source": [
    "# Assignment 4 Constructing Confidence Interval\n",
    "\n",
    "### Reads data, finds info of entire dataframe with df.info(). Gives dtype, non-null, column names / number. \n",
    "### Uses df.describe() to get statistical summaries of the data.\n",
    "\n",
    "### Uses df.hist() to plot histograms of all the data.\n",
    "\n",
    "### Uses pd.get_dummies to get categorical values.\n",
    "\n",
    "\n",
    "### Uses seaborn.jointplot to inspect relation between two variables.\n",
    "\n",
    "\n",
    "### Applies a logarithm function to functions which could use them to better evenly distribute them. Plots them w jointplot.\n",
    "\n",
    "\n",
    "### Uses df.cor() to find the relation between the features and the target.\n",
    "\n",
    "\n",
    "\n",
    "## Splits data, uses LinearRegression() to train, then finds mean_squared_error for prediction and generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc507621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
